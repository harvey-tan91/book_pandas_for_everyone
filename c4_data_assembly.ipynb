{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy data is a framework to structure data sets so that they can be easily analyzed\n",
    "\n",
    "# Each row is an observation \n",
    "# Each column is a variable \n",
    "# Each type of observational unit forms a table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation can be thought of appending rows or columns \n",
    "# this approach is possible if your data was split into parts or if \n",
    "# you want to perform a calculation that you want to append to your existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(r\"C:\\Users\\tanzh\\Documents\\Python\\Pandas for Everyone\\datasets\\c4\\concat1.csv\")\n",
    "data2 = pd.read_csv(r\"C:\\Users\\tanzh\\Documents\\Python\\Pandas for Everyone\\datasets\\c4\\concat2.csv\")\n",
    "data3 = pd.read_csv(r\"C:\\Users\\tanzh\\Documents\\Python\\Pandas for Everyone\\datasets\\c4\\concat3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenting simply stack the dataframes on top of each other \n",
    "row_concat = pd.concat([data1, data2, data3]) # all the dataframes to be concatenated are passed in a list\n",
    "print(row_concat)\n",
    "# noticed that the row names (row indices), they are also stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_concat.iloc[3] # this print the row item with an index label of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_concat.iloc[7] # this print the row item with an index label of 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_concat.loc[1] # this print out all the index label of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new series to append to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row_series = pd.Series([\"new1a\",\"new2b\",\"new3c\",\"new4d\",\"new5e\"])\n",
    "print(new_row_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now attempt to add the data series created above to data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([data1, new_row_series])\n",
    "print(x)\n",
    "\n",
    "# the above create a new column \n",
    "# the items in new_row_series were added as individual row items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fix the above problem, we need to turn our Series into a DataFrame\n",
    "# the dataframe object will contain one row of items and the name of the columns to blind the items tp\n",
    "\n",
    "new_rows_dataframe = pd.DataFrame([[\"new1a\",\"new2b\",\"new3c\",\"new4d\",\"new5e\"]], columns = [\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "print(new_rows_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data2, new_rows_dataframe]) # this concat data2 and the new_rows_dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat is a general function that can concatenate multiple things at once\n",
    "# if you need to append a single object to a existing dataframe, the append function can handle such task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_append = data1.append(data2) # this append data1 to data2 \n",
    "print(to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_append_new = data2.append(new_rows_dataframe)\n",
    "print(to_append_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using python dictionary \n",
    "\n",
    "data_dict = { \"A\" : \"new1a\" , \n",
    "              \"B\" : \"new2b\" , \n",
    "              \"C\" : \"new3c\" , \n",
    "              \"D\" : \"new4d\" \n",
    "            }\n",
    "\n",
    "to_append_using_dict = data1.append(data_dict, ignore_index = True)\n",
    "print(to_append_using_dict)\n",
    "\n",
    "# noticed that the index was increased by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignoring the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ignore_index = pd.concat([data1, data2, data3], ignore_index = True)\n",
    "print(data_ignore_index)\n",
    "\n",
    "# noticed the index label is not repeated and instead is smooth running number from 0 to 12 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the default value for the axis is 0 which means it will concat data in a row-wise fashion\n",
    "# if the axis is 1, it will concat data in a column-wise fashion\n",
    "\n",
    "data_col_concat = pd.concat([data1,data2,data3], axis = 1 )\n",
    "print(data_col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can retrieve a subset of the column that have the same name using the name of the columns. for example\n",
    "\n",
    "print(data_col_concat[\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add a new column can be done without using any specific Pandas function \n",
    "\n",
    "data_col_concat[\"new_columns\"] = [\"new1\", \"new2\", \"new3\", \"new4\", \"new5\"]\n",
    "print(data_col_concat)\n",
    "\n",
    "# note that you need to add in the same number of data points (row-wise) as per the original dataframe\n",
    "# see below for an example\n",
    "# data_col_concat[\"new_columns1\"] = [\"new1\", \"new2\", \"new3\", \"new4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation with different indices\n",
    "Concatenate rows with different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above examples assumes that we are performing simple row and columns concatenation where :\n",
    "## new rows had the same column names or\n",
    "## new columns had the same row indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns = [\"A\", \"B\", \"C\", \"D\"]\n",
    "data2.columns = [\"E\", \"F\", \"G\", \"H\", \"I\"]\n",
    "data3.columns = [\"A\", \"C\", \"F\", \"H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "A    B    C    D    E    F    G    H    I\n0   a0   b0   c0   d0  NaN  NaN  NaN  NaN  NaN\n1   a1   b1   c1   d1  NaN  NaN  NaN  NaN  NaN\n2   a2   b2   c2   d2  NaN  NaN  NaN  NaN  NaN\n3   a3   b3   c3   d3  NaN  NaN  NaN  NaN  NaN\n0  NaN  NaN  NaN  NaN   a4   b4   c4   d4   e4\n1  NaN  NaN  NaN  NaN   a5   b5   c5   d5   e5\n2  NaN  NaN  NaN  NaN   a6   b6   c6   d6  NaN\n3  NaN  NaN  NaN  NaN   a7   b7   c7   d7  NaN\n0   a8  NaN   b8  NaN  NaN   c8  NaN   d8  NaN\n1   a9  NaN   b9  NaN  NaN   c9  NaN   d9  NaN\n2  a10  NaN  b10  NaN  NaN  c10  NaN  d10  NaN\n3  a11  NaN  b11  NaN  NaN  c11  NaN  d11  NaN\n4  a12  NaN  b12  NaN  NaN  c12  NaN  d12  NaN\n"
    }
   ],
   "source": [
    "new_table = pd.concat([data1,data2,data3])\n",
    "print(new_table)\n",
    "\n",
    "# row items across the data files that share the same column name will be group toegther under the same column name in the new dataframe object\n",
    "# note that there is parameter in concat function known as join, which by default has a value of \"outer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Empty DataFrame\nColumns: []\nIndex: [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 4]\n"
    }
   ],
   "source": [
    "# if we want to keep only the columns that are shared among the data sets , we can ;\n",
    "\n",
    "table_with_common_col = pd.concat([data1,data2,data3], join = \"inner\")\n",
    "print(table_with_common_col)\n",
    "\n",
    "# we are looking for commonality column-wise between data1, data2 and data3 \n",
    "# if there is no commonality column-wise between all of them, even if there is commonality column-wise between data1 and data3, it will return a empty dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "A    C\n0   a0   c0\n1   a1   c1\n2   a2   c2\n3   a3   c3\n4   a8   b8\n5   a9   b9\n6  a10  b10\n7  a11  b11\n8  a12  b12\n"
    }
   ],
   "source": [
    "table_with_common_col_revised = pd.concat([data1,data3],ignore_index = True, join = \"inner\")\n",
    "print(table_with_common_col_revised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation with different indices\n",
    "Concatenate columns with different rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.index = [0,1,2,3]\n",
    "data2.index = [4,5,6,7]\n",
    "data3.index = [0,2,4,6,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "A    B    C    D    E    F    G    H    I    A    C    F    H\n0   a0   b0   c0   d0  NaN  NaN  NaN  NaN  NaN   a8   b8   c8   d8\n1   a1   b1   c1   d1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n2   a2   b2   c2   d2  NaN  NaN  NaN  NaN  NaN   a9   b9   c9   d9\n3   a3   b3   c3   d3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n4  NaN  NaN  NaN  NaN   a4   b4   c4   d4   e4  a10  b10  c10  d10\n5  NaN  NaN  NaN  NaN   a5   b5   c5   d5   e5  NaN  NaN  NaN  NaN\n6  NaN  NaN  NaN  NaN   a6   b6   c6   d6  NaN  a11  b11  c11  d11\n7  NaN  NaN  NaN  NaN   a7   b7   c7   d7  NaN  NaN  NaN  NaN  NaN\n8  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  a12  b12  c12  d12\n"
    }
   ],
   "source": [
    "table = pd.concat([data1,data2,data3], axis = 1)\n",
    "# when we concat along the axis 1, the new dataframe will be added in a column-wise fashion and matched against their respective row indices \n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Empty DataFrame\nColumns: [A, B, C, D, E, F, G, H, I, A, C, F, H]\nIndex: []\n"
    }
   ],
   "source": [
    "# if we want to keep only the row indices that are shared among the data file, we can \n",
    "\n",
    "table_with_common_rol = pd.concat([data1,data2,data3], axis = 1, join = \"inner\")\n",
    "print(table_with_common_rol)\n",
    "\n",
    "# we are looking for commonality row-wise between data1, data2 and data3 \n",
    "# if there is no commonality row-wise between all of them, even if there is commonality row-wise between data1 and data3, it will return a empty dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "A   B   C   D   A   C   F   H\n0  a0  b0  c0  d0  a8  b8  c8  d8\n2  a2  b2  c2  d2  a9  b9  c9  d9\n"
    }
   ],
   "source": [
    "table_with_common_rol_revised = pd.concat([data1,data3], axis = 1, join = \"inner\")\n",
    "print(table_with_common_rol_revised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Multiple Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas has a pd.join command that uses pd.merge under the hood, join will merge dataframe objects based on an index but the merge command is much more explicit and flexible\n",
    "# note that merge is a DataFrame method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = pd.read_csv(r\"C:\\Users\\tanzh\\Documents\\Python\\Pandas for Everyone\\datasets\\c4\\survey_person.csv\")\n",
    "site = pd.read_csv(r\"C:\\Users\\tanzh\\Documents\\Python\\Pandas for Everyone\\datasets\\c4\\survey_site.csv\")\n",
    "survey = pd.read_csv(r\"C:\\Users\\tanzh\\Documents\\Python\\Pandas for Everyone\\datasets\\c4\\survey_survey.csv\")\n",
    "visited = pd.read_csv(r\"C:\\Users\\tanzh\\Documents\\Python\\Pandas for Everyone\\datasets\\c4\\survey_visited.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-to-One Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the simplest type of merge, we have two dataframes where we want to join one column to another column, and where the column we want to join do not contain any duplicate values\n",
    "# the number of row items between the two dataframes are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ident   site       dated\n0    619   DR-1  1927-02-08\n2    734   DR-3  1939-01-07\n6    837  MSK-4  1932-01-14\n"
    }
   ],
   "source": [
    "visited_subset = visited.loc[[0,2,6],] # this extract row items with index labels 0,2,6 and assign to the said variable\n",
    "print(visited_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    name    lat    long\n0   DR-1 -49.85 -128.57\n1   DR-3 -47.15 -126.72\n2  MSK-4 -48.87 -123.40",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>lat</th>\n      <th>long</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>DR-1</td>\n      <td>-49.85</td>\n      <td>-128.57</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>DR-3</td>\n      <td>-47.15</td>\n      <td>-126.72</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>MSK-4</td>\n      <td>-48.87</td>\n      <td>-123.40</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a one-to-one merge as follows: \n",
    "\n",
    "# in the merge function : \n",
    "#1 the dataframe that is being called will be refered to the one on the 'left\n",
    "#1a in the below example, site is the dataframe that is on the 'left'\n",
    "#2 'visited_subset' is the dataframe that is on the 'right'\n",
    "\n",
    "# how to match\n",
    "# we are matching the entries with the 'name' columns that are in both of the dataframes\n",
    "# if both the dataframes do not contain columns of the same names, we have to define the left_on and right_on\n",
    "\n",
    "o2o_merge_table = site.merge(visited_subset, left_on=\"name\", right_on=\"site\")\n",
    "print(o2o_merge_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-One Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this kind of merge, one of the dataframes has key values that repeat\n",
    "# the dataframe that contain the single observations will then be duplicated in the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "name    lat    long  ident   site       dated\n0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n6   DR-3 -47.15 -126.72    752   DR-3         NaN\n7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
    }
   ],
   "source": [
    "m2o_merge_table = site.merge(visited, left_on=\"name\", right_on=\"site\")\n",
    "print(m2o_merge_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-many Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use many-to-many merge where we want to perform a match based on mutiple columns \n",
    "# suppose we have the following dataframes, person, survey, visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ident   personal   family  taken person quant  reading\n0   dyer    William     Dyer    619   dyer   rad     9.82\n1   dyer    William     Dyer    619   dyer   sal     0.13\n2   dyer    William     Dyer    622   dyer   rad     7.80\n3   dyer    William     Dyer    622   dyer   sal     0.09\n4     pb      Frank  Pabodie    734     pb   rad     8.41\n5     pb      Frank  Pabodie    734     pb  temp   -21.50\n6     pb      Frank  Pabodie    735     pb   rad     7.22\n7     pb      Frank  Pabodie    751     pb   rad     4.35\n8     pb      Frank  Pabodie    751     pb  temp   -18.50\n9   lake   Anderson     Lake    734   lake   sal     0.05\n10  lake   Anderson     Lake    751   lake   sal     0.10\n11  lake   Anderson     Lake    752   lake   rad     2.19\n12  lake   Anderson     Lake    752   lake   sal     0.09\n13  lake   Anderson     Lake    752   lake  temp   -16.00\n14  lake   Anderson     Lake    837   lake   rad     1.46\n15  lake   Anderson     Lake    837   lake   sal     0.21\n16   roe  Valentina  Roerich    752    roe   sal    41.60\n17   roe  Valentina  Roerich    837    roe   sal    22.50\n18   roe  Valentina  Roerich    844    roe   rad    11.25",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ident</th>\n      <th>personal</th>\n      <th>family</th>\n      <th>taken</th>\n      <th>person</th>\n      <th>quant</th>\n      <th>reading</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>dyer</td>\n      <td>William</td>\n      <td>Dyer</td>\n      <td>619</td>\n      <td>dyer</td>\n      <td>rad</td>\n      <td>9.82</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>dyer</td>\n      <td>William</td>\n      <td>Dyer</td>\n      <td>619</td>\n      <td>dyer</td>\n      <td>sal</td>\n      <td>0.13</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>dyer</td>\n      <td>William</td>\n      <td>Dyer</td>\n      <td>622</td>\n      <td>dyer</td>\n      <td>rad</td>\n      <td>7.80</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>dyer</td>\n      <td>William</td>\n      <td>Dyer</td>\n      <td>622</td>\n      <td>dyer</td>\n      <td>sal</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>pb</td>\n      <td>Frank</td>\n      <td>Pabodie</td>\n      <td>734</td>\n      <td>pb</td>\n      <td>rad</td>\n      <td>8.41</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>pb</td>\n      <td>Frank</td>\n      <td>Pabodie</td>\n      <td>734</td>\n      <td>pb</td>\n      <td>temp</td>\n      <td>-21.50</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>pb</td>\n      <td>Frank</td>\n      <td>Pabodie</td>\n      <td>735</td>\n      <td>pb</td>\n      <td>rad</td>\n      <td>7.22</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>pb</td>\n      <td>Frank</td>\n      <td>Pabodie</td>\n      <td>751</td>\n      <td>pb</td>\n      <td>rad</td>\n      <td>4.35</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>pb</td>\n      <td>Frank</td>\n      <td>Pabodie</td>\n      <td>751</td>\n      <td>pb</td>\n      <td>temp</td>\n      <td>-18.50</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>lake</td>\n      <td>Anderson</td>\n      <td>Lake</td>\n      <td>734</td>\n      <td>lake</td>\n      <td>sal</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>lake</td>\n      <td>Anderson</td>\n      <td>Lake</td>\n      <td>751</td>\n      <td>lake</td>\n      <td>sal</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>lake</td>\n      <td>Anderson</td>\n      <td>Lake</td>\n      <td>752</td>\n      <td>lake</td>\n      <td>rad</td>\n      <td>2.19</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>lake</td>\n      <td>Anderson</td>\n      <td>Lake</td>\n      <td>752</td>\n      <td>lake</td>\n      <td>sal</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>lake</td>\n      <td>Anderson</td>\n      <td>Lake</td>\n      <td>752</td>\n      <td>lake</td>\n      <td>temp</td>\n      <td>-16.00</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>lake</td>\n      <td>Anderson</td>\n      <td>Lake</td>\n      <td>837</td>\n      <td>lake</td>\n      <td>rad</td>\n      <td>1.46</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>lake</td>\n      <td>Anderson</td>\n      <td>Lake</td>\n      <td>837</td>\n      <td>lake</td>\n      <td>sal</td>\n      <td>0.21</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>roe</td>\n      <td>Valentina</td>\n      <td>Roerich</td>\n      <td>752</td>\n      <td>roe</td>\n      <td>sal</td>\n      <td>41.60</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>roe</td>\n      <td>Valentina</td>\n      <td>Roerich</td>\n      <td>837</td>\n      <td>roe</td>\n      <td>sal</td>\n      <td>22.50</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>roe</td>\n      <td>Valentina</td>\n      <td>Roerich</td>\n      <td>844</td>\n      <td>roe</td>\n      <td>rad</td>\n      <td>11.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "ps = person.merge(survey, left_on= \"ident\", right_on=\"person\")\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ident   site       dated  taken person quant  reading\n0     619   DR-1  1927-02-08    619   dyer   rad     9.82\n1     619   DR-1  1927-02-08    619   dyer   sal     0.13\n2     622   DR-1  1927-02-10    622   dyer   rad     7.80\n3     622   DR-1  1927-02-10    622   dyer   sal     0.09\n4     734   DR-3  1939-01-07    734     pb   rad     8.41\n5     734   DR-3  1939-01-07    734   lake   sal     0.05\n6     734   DR-3  1939-01-07    734     pb  temp   -21.50\n7     735   DR-3  1930-01-12    735     pb   rad     7.22\n8     735   DR-3  1930-01-12    735    NaN   sal     0.06\n9     735   DR-3  1930-01-12    735    NaN  temp   -26.00\n10    751   DR-3  1930-02-26    751     pb   rad     4.35\n11    751   DR-3  1930-02-26    751     pb  temp   -18.50\n12    751   DR-3  1930-02-26    751   lake   sal     0.10\n13    752   DR-3         NaN    752   lake   rad     2.19\n14    752   DR-3         NaN    752   lake   sal     0.09\n15    752   DR-3         NaN    752   lake  temp   -16.00\n16    752   DR-3         NaN    752    roe   sal    41.60\n17    837  MSK-4  1932-01-14    837   lake   rad     1.46\n18    837  MSK-4  1932-01-14    837   lake   sal     0.21\n19    837  MSK-4  1932-01-14    837    roe   sal    22.50\n20    844   DR-1  1932-03-22    844    roe   rad    11.25\n"
    }
   ],
   "source": [
    "vs = visited.merge(survey, left_on = \"ident\", right_on = \"taken\" )\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_vs = ps.merge(vs, left_on = [\"ident\", \"taken\",\"quant\",\"reading\"], right_on = [\"person\",\"ident\",\"quant\",\"reading\"])\n",
    "\n",
    "print(ps_vs)\n",
    "\n",
    "# pandas will automatically add a suffix to a column name if there are collusion in the name\n",
    "# in the output, the _x refer to the values from the left dataframe and the _y suffix refer to the values that come from the right dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda6db2893f0e1b4b6ea66d23044bec9473",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}